{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ARF file data/bug-149/acisf00308_000N001_r0044_arf3.fits\n",
      "read RMF file data/bug-149/acisf00308_000N001_r0044_rmf3.fits\n",
      "read background file data/bug-149/acisf00308_000N001_r0044_pha3.fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "group_counts() got an unexpected keyword argument 'bkg_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-221d5d361905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbkg_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# what should happen? How does that affect the data?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: group_counts() got an unexpected keyword argument 'bkg_id'"
     ]
    }
   ],
   "source": [
    "from sherpa.astro import ui\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "ui.load_pha('data/bug-149/acisf00308_000N001_r0044_pha3.fits.gz', use_errors=True)\n",
    "\n",
    "# test case 1: expected results when grouping the background independently from the signal\n",
    "\n",
    "data = ui.get_data()\n",
    "\n",
    "data.group_counts(16)\n",
    "data.group_counts(num=10, bkg_id=1)\n",
    "\n",
    "# what should happen? How does that affect the data?\n",
    "# also notice how this doesn't work... see the docs at http://cxc.harvard.edu/sherpa/ahelp/group_sherpa.html\n",
    "# or help(group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   7.   0.   7.   1.   9.   9.   9.   3.  12.  11.   7.   3.  11.   6.\n",
      "  10.  10.  12.  13.   9.   9.   3.  10.   3.   9.   2.   8.   3.   7.   9.\n",
      "   8.   9.   9.   1.   9.   7.   9.   7.   7.   5.   8.   8.   8.   7.   0.\n",
      "   8.   5.   8.   1.   7.   1.   6.   5.   7.   2.   9.   5.   8.   1.   9.\n",
      "   5.   7.   4.   8.   8.   8.   9.   6.   1.   6.   6.   6.   2.  10.   3.]\n"
     ]
    }
   ],
   "source": [
    "# test case 2: group_snr_adapt()\n",
    "ui.ungroup()\n",
    "ui.group_adapt_snr(3)\n",
    "\n",
    "print ui.get_data().get_dep(filter=True)\n",
    "\n",
    "# what do we expect from adaptive grouping?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ARF file /stage/pool7/jbudynk/bug_reports/nlee_grouping/18076.corr.arf\n",
      "read RMF file /stage/pool7/jbudynk/bug_reports/nlee_grouping/18076.rmf\n",
      "read ARF (background) file /stage/pool7/jbudynk/bug_reports/nlee_grouping/18076_bkg.arf\n",
      "read RMF (background) file /stage/pool7/jbudynk/bug_reports/nlee_grouping/18076_bkg.rmf\n",
      "read background file /stage/pool7/jbudynk/bug_reports/nlee_grouping/18076_bkg.pi\n",
      "\n",
      " data before ignore_bad() is called\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  2.  1.\n",
      "  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  5.\n",
      "  6.  6.  7.  5.  6.  6.  5.  5.  6.  5.  5.  5.  5.  5.  6.  5.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.]\n",
      "\n",
      " data after ignore_bad() is called\n",
      "[ 5.  6.  6.  7.  5.  6.  6.  5.  5.  6.  5.  5.  5.  5.  5.  6.  5.]\n",
      "\n",
      " ungrouped the data, then regrouped in Sherpa\n",
      "[ 6.  5.  6.  5.  5.  5.  6.  5.  5.  6.  5.  5.  5.  5.  5.  6.  5.]\n",
      "\n",
      " after calling ignore_bad() on dataset\n",
      "[ 5.  6.  6.  5.  6.  5.  5.  5.  6.  5.  5.  6.  5.  5.  5.  5.  5.  6.\n",
      "  5.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "# test case 3: Nick Lee's bug\n",
    "nlee_file = '/stage/pool7/jbudynk/bug_reports/nlee_grouping/18076_bin5.pi' # proprietary - not in repo\n",
    "ui.clean()\n",
    "ui.load_pha(nlee_file)\n",
    "\n",
    "rmf = ui.get_rmf()\n",
    "arf = ui.get_arf()\n",
    "bkg_scale = ui.get_bkg_scale()\n",
    "\n",
    "# the data has already been grouped\n",
    "data = ui.get_data()\n",
    "\n",
    "print \"\\n data before ignore_bad() is called\"\n",
    "print data.get_dep(filter=True)\n",
    "\n",
    "# ignore bad data\n",
    "data.ignore_bad()\n",
    "\n",
    "print \"\\n data after ignore_bad() is called\"\n",
    "print data.get_dep(filter=True)\n",
    "\n",
    "# now regroup the data\n",
    "data.ungroup()\n",
    "data.group_counts(5)\n",
    "\n",
    "print \"\\n ungrouped the data, then regrouped in Sherpa\"\n",
    "print data.get_dep(filter=True)\n",
    "\n",
    "# ignore any bad data\n",
    "data.ignore_bad()\n",
    "\n",
    "print \"\\n after calling ignore_bad() on dataset\"\n",
    "print data.get_dep(filter=True)\n",
    "\n",
    "# notice that the arrays are different. What should happen instead?\n",
    "# We can take a look at Omar's email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ARF file data/bug-149/acisf00308_000N001_r0044_arf3.fits\n",
      "read RMF file data/bug-149/acisf00308_000N001_r0044_rmf3.fits\n",
      "read background file data/bug-149/acisf00308_000N001_r0044_pha3.fits\n",
      "\n",
      " expected grouped and filtered array: \n",
      "[19, 18, 16, 21, 18, 19, 16, 17, 19, 16, 16, 17, 16, 17, 16, 17, 16, 16, 16, 17, 16, 16, 16, 16, 16, 16, 16]\n",
      "\n",
      " actual grouped and filtered array: \n",
      "[ 17.  16.  16.  17.  17.  17.  16.  16.  17.  17.  19.  16.  16.  17.  16.\n",
      "  17.  16.  17.  16.  16.  16.  17.  16.  16.  16.  16.  16.  16.  16.  13.]\n",
      "\n",
      " after ignore_bad(): \n",
      "WARNING: filtering grouped data with quality flags, previous filters deleted\n",
      "[ 17.  16.  16.  17.  17.  17.  16.  16.  17.  17.  19.  16.  16.  17.  16.\n",
      "  17.  16.  17.  16.  16.  16.  17.  16.  16.  16.  16.  16.  16.  16.]\n"
     ]
    }
   ],
   "source": [
    "# issue-149. See https://github.com/sherpa/sherpa/issues/149 for more info.\n",
    "# It's very similar, if not the same issue as Nick's bug report.\n",
    "\n",
    "ui.load_pha(0,\"data/bug-149/acisf00308_000N001_r0044_pha3.fits.gz\", use_errors=True)\n",
    "\n",
    "data = ui.get_data(0)\n",
    "\n",
    "#filter and group data\n",
    "data.notice(0.5, 7.0)\n",
    "data.group_counts(16)\n",
    "\n",
    "# the expected grouped counts after filtering\n",
    "new_y = [19, 18, 16, 21, 18, 19, 16, 17, 19, 16, 16, 17, 16, 17,\n",
    "         16, 17, 16, 16, 16, 17, 16, 16, 16, 16, 16, 16, 16]\n",
    "\n",
    "print \"\\n expected grouped and filtered array: \"\n",
    "print new_y\n",
    "\n",
    "# the array after grouping and filtering\n",
    "print \"\\n actual grouped and filtered array: \"\n",
    "print data.get_dep(filter=True)\n",
    "\n",
    "# what's happening is that group_counts() is ignoring the filter.\n",
    "# instead, I think it should take the filter into consideration before grouping\n",
    "# then group only the data within the notice range.\n",
    "\n",
    "# if we ignore the bad data points with ignore_bad(), we get the warning Nick's\n",
    "# bug misses to show\n",
    "print \"\\n after ignore_bad(): \"\n",
    "data.ignore_bad()\n",
    "print data.get_dep(filter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
